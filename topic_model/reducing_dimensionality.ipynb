{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing dimensionality for topic models\n",
    "\n",
    "This project was concerned with classifying deceptive from authentic reviews. This is a follow-up to the work been done so far and it specifically touches on how we can further improve the classifier's performance by applying a form of feature selection. To do this, I computed the mutual information for each bigram in the corpus and then removed bigrams which did not pass a certain threshold. \n",
    "\n",
    "The information threshold was set at 0.055 (13% of features removed).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andreas\\Anaconda2\\lib\\site-packages\\gensim-2.3.0-py2.7-win-amd64.egg\\gensim\\utils.py:865: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score,precision_score, make_scorer,fbeta_score\n",
    "from sklearn import svm, tree\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score, ShuffleSplit,train_test_split\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "from gensim import models,corpora,similarities\n",
    "from nltk.util import ngrams\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "#import main dataset for training / testing\n",
    "\n",
    "def import_data():\n",
    "    \n",
    "    reviews = pd.read_csv('deceptive-opinion.csv')\n",
    "    reviews_txt =  reviews['text']\n",
    "    \n",
    "    labels = reviews['deceptive'].values\n",
    "    labels = (labels == 'truthful') * 1\n",
    "    labels = pd.Series(labels)\n",
    "    \n",
    "    truthful_indices = labels[labels == 1].index.values\n",
    "    deceptive_indices = labels[labels == 0].index.values\n",
    "                              \n",
    "    return reviews_txt, labels, truthful_indices, deceptive_indices\n",
    "\n",
    "def bigram_info(txt,inds1,inds2,freq,num_bins):\n",
    "          \n",
    "    num_docs = txt.shape[0]\n",
    "      \n",
    "    p_c1 = float(len(inds1)) / num_docs\n",
    "    \n",
    "    p_c2 = float(len(inds2)) / num_docs\n",
    "    \n",
    "    p_c = np.array([[p_c1],[p_c2]])\n",
    "    \n",
    "    type_entropy = -np.sum(p_c * np.log(p_c))\n",
    "    \n",
    "    ngram_counts = CountVectorizer(analyzer='word', ngram_range=(2, 2), min_df=1)\n",
    "    bigram_counts = ngram_counts.fit_transform(txt)\n",
    "\n",
    "    num_bigrams = len(ngram_counts.vocabulary_.values())\n",
    "\n",
    "    bigram_vocab = [None] * num_bigrams\n",
    "\n",
    "    for n in range(0,num_bigrams-1):\n",
    "        \n",
    "        index = ngram_counts.vocabulary_.values()[n]\n",
    "        \n",
    "        bigram_vocab[index] = ngram_counts.vocabulary_.keys()[n]\n",
    "           \n",
    "    \n",
    "    subset_indices = (np.where(np.sum(bigram_counts.toarray(),axis=0)>freq))[0]\n",
    "    \n",
    "    bigram_vocab_subset = [bigram_vocab[i] for i in subset_indices]\n",
    "\n",
    "    bigram_counts_subset = bigram_counts[:,subset_indices]\n",
    "    \n",
    "    num_bigrams_subset = np.shape(bigram_counts_subset)[1]\n",
    "    \n",
    "    info_gain = np.zeros(num_bigrams_subset)\n",
    "    \n",
    "    bins = range(0,num_bins)\n",
    "    \n",
    "    for n in range(0,num_bigrams_subset):\n",
    "            \n",
    "        p_wc = np.zeros((2,len(bins)-1))\n",
    "        \n",
    "        b, bin_edges = np.histogram(bigram_counts_subset[inds1,n].toarray(),bins=bins)\n",
    "        \n",
    "        p_wc[0,:] = b.astype('float') / len(inds1)\n",
    "        \n",
    "        b, bin_edges = np.histogram(bigram_counts_subset[inds2,n].toarray(),bins=bins)\n",
    "        \n",
    "        p_wc[1,:] = b.astype('float') / len(inds2)\n",
    "        \n",
    "        b, bin_edges = np.histogram(bigram_counts_subset[:,n].toarray(),bins=bins)\n",
    "        \n",
    "        p_w = b.astype('float') / num_docs\n",
    "        \n",
    "        p_cw = np.multiply(p_wc,p_c) / p_w     \n",
    "        \n",
    "        conditional_entropy = -np.nansum((p_w * p_cw) * np.log(p_cw))\n",
    "        \n",
    "        info_gain[n] = ((type_entropy - conditional_entropy) / type_entropy) * 100\n",
    "        \n",
    "        names = np.array(bigram_vocab_subset)    \n",
    "        \n",
    "        info_per_bigram = dict(zip(names,info_gain))\n",
    "    \n",
    "    return info_per_bigram\n",
    "\n",
    "\n",
    "def remove_low_info(txt,low_info):\n",
    "    \n",
    "    num_docs = txt.shape[0]\n",
    "    \n",
    "    bigrams_docs = [None] * num_docs\n",
    "        \n",
    "    for i in range(0,num_docs):\n",
    "        \n",
    "        text=txt[i].lower().translate(None, string.punctuation)\n",
    "        \n",
    "        token = nltk.word_tokenize(text)\n",
    "        \n",
    "        bigrams = ngrams(token,2)\n",
    "        \n",
    "        valid_bigrams = [bigram for bigram in bigrams if ' '.join(bigram) not in low_info]\n",
    "    \n",
    "        bigrams_docs[i] = ['_'.join(valid_bigrams[n]) for n,item in enumerate(valid_bigrams)]\n",
    "    \n",
    "    return bigrams_docs\n",
    "\n",
    "def train_classifier(clf,parameters,scorer,X,y):\n",
    "        \n",
    "    cv_sets = KFold(n_splits = 5, shuffle = True, random_state = 0)\n",
    "    \n",
    "    print \"Parameter searching...\"\n",
    "    grid_obj = GridSearchCV(clf, parameters,cv=cv_sets,scoring=scorer)\n",
    "    \n",
    "    grid_fit = grid_obj.fit(X,y)\n",
    "        \n",
    "    best_clf = grid_fit.best_estimator_\n",
    "      \n",
    "    return best_clf,grid_fit\n",
    "    \n",
    "\n",
    "def test_classifier(best_clf,X_test,y_test):\n",
    " \n",
    "    best_predictions = best_clf.predict(X_test)\n",
    "    \n",
    "    performance = {'accuracy': accuracy_score(best_predictions,y_test),\n",
    "                   'recall': recall_score(best_predictions,y_test),\n",
    "                   'precision': precision_score(best_predictions,y_test)\n",
    "                   }\n",
    "    \n",
    "    return performance\n",
    "\n",
    "def construct_corpus(docs):\n",
    "    \n",
    "        num_docs = len(docs)\n",
    "    \n",
    "        dictionary=corpora.Dictionary(docs)\n",
    "\n",
    "        corpus = [dictionary.doc2bow(text) for text in docs]\n",
    "        \n",
    "        return corpus,dictionary\n",
    "\n",
    "def extract_topic_dists(corpus,dictionary,num_topics,chunksize,passes):\n",
    "    \n",
    "    num_docs = np.shape(corpus)[0]\n",
    "    \n",
    "    model = models.LdaModel(corpus, id2word=dictionary, num_topics=num_topics,alpha = 'auto',eta='auto',random_state=0, chunksize=chunksize, passes=passes)\n",
    "    \n",
    "    topic_dists = np.zeros([num_docs,num_topics])\n",
    "    \n",
    "    for i,item in enumerate(corpus):\n",
    "        \n",
    "        dists = model.get_document_topics(item)\n",
    "        \n",
    "        indices = dict(dists).keys()\n",
    "        \n",
    "        vals = dict(dists).values()\n",
    "        \n",
    "        topic_dists[i,indices] = vals\n",
    "                   \n",
    "    return topic_dists\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews_txt, labels, truthful_indices, deceptive_indices = import_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's extract bigram mutual information with respect to category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andreas\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:88: RuntimeWarning: invalid value encountered in divide\n",
      "C:\\Users\\andreas\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:90: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\andreas\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:90: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    }
   ],
   "source": [
    "info_per_bigram = bigram_info(reviews_txt,truthful_indices,deceptive_indices,0,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rank found bigrams by info and set MI threshold at 0.05%. Any bigrams with lower values will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.130117994454\n"
     ]
    }
   ],
   "source": [
    "ranked_bigrams = np.array(info_per_bigram.keys())[np.argsort(info_per_bigram.values())]\n",
    "ranked_vals = np.array(info_per_bigram.values())[np.argsort(info_per_bigram.values())]\n",
    "\n",
    "low_info_bigrams = ranked_bigrams[:np.sum(ranked_vals < 0.055)]\n",
    "\n",
    "print(len(low_info_bigrams)/float(len(info_per_bigram)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have the ranked bigrams, let's remove them from the reviews before any further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigrams_docs = remove_low_info(reviews_txt,low_info_bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Form corpus and extract topic distributions for each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus,dictionary = construct_corpus(bigrams_docs)\n",
    "topic_dists = extract_topic_dists(corpus,dictionary,100,400,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go through the classification process. 5-fold cross-validation with gridsearch of 2 (kernels) x 6 (C values) x 9 (gamma values) parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter searching...\n"
     ]
    }
   ],
   "source": [
    "clf_gridsearch = svm.SVC(random_state=0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(topic_dists, labels, test_size = 0.2, random_state = 0)\n",
    "scorer = make_scorer(fbeta_score,beta=0.5)\n",
    "\n",
    "parameters_TM = {\"kernel\": ['rbf','linear'], \"C\": [0.1,0.2,0.4,0.6,0.8,1,10], \"gamma\": np.logspace(-1,1,9)}\n",
    "\n",
    "best_clf_TM,grid_fit_TM = train_classifier(clf_gridsearch,parameters_TM,scorer,X_train,y_train)\n",
    "\n",
    "performance_TM = test_classifier(best_clf_TM,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the classifier parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91167607961\n",
      "0.892626131953\n",
      "{'recall': 0.90196078431372551, 'precision': 0.89032258064516134, 'accuracy': 0.90000000000000002}\n",
      "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.56234132519,\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=0,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print(grid_fit_TM.best_score_)\n",
    "best_predictions = best_clf_TM.predict(X_test)\n",
    "print(fbeta_score(best_predictions,y_test,0.5))\n",
    "\n",
    "print(performance_TM)\n",
    "print(best_clf_TM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Form a distribution of accuracies to see where we stand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13cad240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean accuracy: 0.93403749999999985\n",
      "Standard deviation: 0.012697785239954251\n",
      "Best accuracy value: 0.97499999999999998\n",
      "Worst accuracy value: 0.89375000000000004\n"
     ]
    }
   ],
   "source": [
    "accuracy_dist = np.zeros(1000)\n",
    "rand_init = np.zeros(1000)\n",
    "\n",
    "for i in range(0,1000):\n",
    "   rand_init[i] = np.floor(np.random.rand(1)[0]*10000)\n",
    "   X_train, X_test, y_train, y_test = train_test_split(topic_dists, labels, test_size = 0.2, random_state = int(rand_init[i]))\n",
    "   best_predictions = best_clf_TM.predict(X_test)\n",
    "   accuracy_dist[i] = accuracy_score(best_predictions,y_test)\n",
    "\n",
    "plt.hist(accuracy_dist,50)\n",
    "plt.show()\n",
    "s = \"\\nMean accuracy: \" + repr(np.mean(accuracy_dist))\n",
    "print(s)\n",
    "s = \"Standard deviation: \" + repr(np.std(accuracy_dist))\n",
    "print(s)\n",
    "s = \"Best accuracy value: \" + repr(np.max(accuracy_dist))\n",
    "print(s)\n",
    "s = \"Worst accuracy value: \" + repr(np.min(accuracy_dist))\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad. \n",
    "\n",
    "First of all, this * **outperforms** the 88% average accuracy of the benchmark model* (please see report.pdf). \n",
    "\n",
    "Secondly, this procedure basically highlights the importance of feature selection. The procedure which comes out of this is first to tokenize the review, remove the bigrams we've found which contain little to no information, and then extract topic distribution for the review (and simultaneously updating the topic model itself). Finally, we can classify the processed document."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
